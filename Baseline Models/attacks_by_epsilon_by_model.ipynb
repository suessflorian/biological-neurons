{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from models import LeNet5_CIFAR, LeNet5_MNIST, SimpleSNN, SimpleParaLif, LargerSNN , GeneralParaLIF, Frankenstein, LeNet5_Flexible, GeneralSNN\n",
    "from scripts import train_model, test_model\n",
    "from utils import load_data, get_object_name, is_leaky, plot_attack, printf\n",
    "from attacks import foolbox_attack, art_attack\n",
    "import foolbox as fb\n",
    "from math import ceil\n",
    "from art.attacks.evasion import SquareAttack, SimBA, BoundaryAttack, HopSkipJump, ZooAttack\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "original_device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "##### Configuration #####\n",
    "\n",
    "append_results_to_csv = True # setting this to False will replace the .csv\n",
    "\n",
    "dataset = 'mnist'\n",
    "plot_params = True\n",
    "\n",
    "batch_size = 256\n",
    "n_epochs = 1\n",
    "\n",
    "num_steps = 20\n",
    "tau_mem = 0.02\n",
    "tau_syn = 0.02\n",
    "spike_mode = 'SB'\n",
    "\n",
    "models = [\n",
    "    LeNet5_MNIST(),\n",
    "    GeneralSNN(layer_sizes=(28*28, 2**9, 2**8, 2**7, 10), num_steps=num_steps),\n",
    "    GeneralParaLIF(layer_sizes=(28*28, 2**9, 2**8, 2**7, 10), device=device, spike_mode=spike_mode, num_steps=num_steps, tau_mem=tau_mem, tau_syn=tau_syn)\n",
    "]\n",
    "\n",
    "noise_steps = torch.arange(4).long()\n",
    "\n",
    "attack_functions = [\n",
    "    art_attack,\n",
    "    foolbox_attack,\n",
    "    foolbox_attack,\n",
    "    foolbox_attack,\n",
    "]\n",
    "\n",
    "attacks = [\n",
    "    SquareAttack,\n",
    "    fb.attacks.LinfFastGradientAttack(),\n",
    "    fb.attacks.LinfDeepFoolAttack(),\n",
    "    fb.attacks.LInfFMNAttack(),\n",
    "]\n",
    "\n",
    "epsilons = [0.01, 0.05, 0.1, 0.25, 0.5, 1]\n",
    "\n",
    "\n",
    "##### Initialisation #####\n",
    "'''\n",
    "devices = [device if not is_leaky(m) else torch.device('cpu') for m in models]\n",
    "models = [load_model(m, 'Baseline Models/models/' + n, d) for m, n, d in zip(models, model_filenames, devices)]\n",
    "print('Models Loaded Successfully')\n",
    "models = [m.to(d) for m, d in zip(models, devices)]\n",
    "'''\n",
    "\n",
    "optimizers = [\n",
    "    torch.optim.Adam,\n",
    "    torch.optim.SGD,\n",
    "    torch.optim.Adamax,\n",
    "]\n",
    "\n",
    "learning_rates = [\n",
    "    0.01,\n",
    "    0.01,\n",
    "    0.001\n",
    "]\n",
    "\n",
    "maximum_batches_to_run_attacks_on = ceil(1000 / batch_size) # can also be set manually\n",
    "\n",
    "\n",
    "##### Initialisation #####\n",
    "\n",
    "optimizers = [opt(m.parameters(), lr) for m, opt, lr in zip(models, optimizers, learning_rates)]\n",
    "devices = [device if not is_leaky(m) else torch.device('cpu') for m in models]\n",
    "models = [m.to(d) for m, d in zip(models, devices)]\n",
    "\n",
    "\n",
    "##### Data #####\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0,0,0), (1,1,1)) if dataset in ['cifar', 'svhn'] else torchvision.transforms.Normalize(0, 1)\n",
    "])\n",
    "\n",
    "train_dataset, train_loader = load_data(dataset=dataset, path='data', train=True, batch_size=batch_size, transforms=transforms)\n",
    "test_dataset, test_loader = load_data(dataset=dataset, path='data', train=False, batch_size=batch_size, transforms=transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack: ABCMeta on model [1/3]: LeNet5_MNIST, epsilon: 0.01, batch: [0/4]<class 'generator'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (MPSFloatType) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m printf(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttack: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattack_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on model [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(models)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, epsilon: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, batch: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaximum_batches_to_run_attacks_on\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(original_device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 34\u001b[0m _, _, perturbed_prediction, original_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mattack_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mattack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m perturbed_prediction \u001b[38;5;241m=\u001b[39m perturbed_prediction\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     41\u001b[0m original_prediction \u001b[38;5;241m=\u001b[39m original_prediction\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Documents/GitHub/biological-neurons/Baseline Models/attacks.py:90\u001b[0m, in \u001b[0;36mart_attack\u001b[0;34m(model, images, labels, attack, epsilons, device, verbose)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     89\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 90\u001b[0m     original_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     91\u001b[0m     perturbed_predictions \u001b[38;5;241m=\u001b[39m model(perturbed_images)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m raw_attack, perturbed_images, perturbed_predictions, original_predictions\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/biological-neurons/Baseline Models/models.py:55\u001b[0m, in \u001b[0;36mLeNet5_MNIST.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 55\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     56\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(x))\n\u001b[1;32m     57\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (MPSFloatType) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "\n",
    "##### Train #####\n",
    "\n",
    "all_results = {\n",
    "    'model':[],\n",
    "    'epochs_trained':[],\n",
    "    'attack':[],\n",
    "    'epsilon':[],\n",
    "    'susceptibility_rate':[],\n",
    "    'train_accuracy':[],\n",
    "    'test_accuracy':[]\n",
    "}\n",
    "\n",
    "print('\\n---------- Training ----------')\n",
    "start_time = time.time()\n",
    "for i, (model, optimizer, device) in enumerate(zip(models, optimizers, devices)):\n",
    "    model_name = get_object_name(model)\n",
    "    print(f'\\nTraining model {i+1}: {model_name}')\n",
    "    model, model_results = train_model(model, \n",
    "                                loader=train_loader, \n",
    "                                optimizer=optimizer,\n",
    "                                n_epochs=n_epochs, \n",
    "                                device=device,\n",
    "                                val_loader=test_loader)\n",
    "    models[i] = model\n",
    "\n",
    "    for attack, attack_function in zip(attacks, attack_functions):\n",
    "        attack_name = get_object_name(attack)\n",
    "        for epsilon in epsilons:\n",
    "            total_successful_attacks, total_successful_classifications = 0, 0\n",
    "            for batch, (images, labels) in enumerate(test_loader):\n",
    "                printf(f'Attack: {attack_name} on model [{i+1}/{len(models)}]: {model_name}, epsilon: {epsilon}, batch: [{batch}/{maximum_batches_to_run_attacks_on}]')\n",
    "                images, labels = images.to(original_device), labels.to(device)\n",
    "\n",
    "                _, _, perturbed_prediction, original_prediction = attack_function(model,\n",
    "                                                                                images,\n",
    "                                                                                labels,\n",
    "                                                                                attack,\n",
    "                                                                                epsilon,\n",
    "                                                                                device)\n",
    "                perturbed_prediction = perturbed_prediction.to(device)\n",
    "                original_prediction = original_prediction.to(device)\n",
    "                correct_pre_attack = (original_prediction == labels)\n",
    "                correct_post_attack = (perturbed_prediction == labels)\n",
    "                n_successful_attacks = (correct_pre_attack & ~correct_post_attack)\n",
    "                \n",
    "                total_successful_attacks += n_successful_attacks.sum().to('cpu').item()\n",
    "                total_successful_classifications += correct_pre_attack.sum().to('cpu').item()\n",
    "                \n",
    "                if batch == maximum_batches_to_run_attacks_on:\n",
    "                    break\n",
    "                \n",
    "            all_results['model'] += [model_name]\n",
    "            all_results['epochs_trained'] += [n_epochs]\n",
    "            all_results['attack'] += [attack_name]\n",
    "            all_results['epsilon'] += [epsilon]\n",
    "            all_results['susceptibility_rate'] += [total_successful_attacks / total_successful_classifications]\n",
    "            all_results['train_accuracy'] += [model_results['train accuracies'][-1]]\n",
    "            all_results['test_accuracy'] += [model_results['val accuracies'][-1]]\n",
    "\n",
    "print(f'\\nTraining time: {time.time() - start_time:.1f} seconds.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Save #####\n",
    "\n",
    "all_results = pd.DataFrame(all_results)\n",
    "\n",
    "path = 'Baseline Models/csvs/' + 'MNIST_attacks_by_epsilon_by_model.csv'\n",
    "\n",
    "if not append_results_to_csv:\n",
    "    while (ans := input('Are you sure you want to OVERWRITE the existing csv? y/n: ')) not in 'yn':\n",
    "        continue\n",
    "    if ans == 'n':\n",
    "        append_results_to_csv = False\n",
    "\n",
    "\n",
    "if append_results_to_csv:\n",
    "    try:\n",
    "        existing = pd.read_csv(path)\n",
    "        final = pd.concat((existing, new))\n",
    "        final.to_csv(path, index=False)\n",
    "    except:\n",
    "        print('No existing CSV found!\\nCreating a new CSV.')\n",
    "        all_results.to_csv(path, index=False)\n",
    "else:\n",
    "    all_results.to_csv(path, index=False)\n",
    "\n",
    "print('\\n\\n---------- CSV SAVED ----------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### Plot #####\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "for result in all_results:    \n",
    "    axs[0].plot(result['epochs'], result['train accuracies'])\n",
    "    axs[1].plot(result['epochs'], result['val accuracies'])\n",
    "\n",
    "for i in [0, 1]:\n",
    "    axs[i].set_xlabel('Epochs')\n",
    "    axs[i].set_ylabel('Accuracy')\n",
    "    axs[i].legend([get_object_name(m, neat=True) for m in models], loc = 'lower right')\n",
    "    \n",
    "axs[0].set_title('Train Accuracies')\n",
    "axs[1].set_title('Test Accuracies')\n",
    "\n",
    "if plot_params:\n",
    "    fig.suptitle(\n",
    "        f'Models: {[get_object_name(m, neat=True) for m in models]}\\n' +\n",
    "        f'Optims: {[get_object_name(o, neat=True) for o in optimizers]}\\n' +\n",
    "        f'lrs: {[lr for lr in learning_rates]}\\n' +\n",
    "        f'Dataset: {dataset.upper()}'\n",
    "    )\n",
    "else:\n",
    "    fig.suptitle(\n",
    "        f'Dataset: {dataset.upper()}'\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
